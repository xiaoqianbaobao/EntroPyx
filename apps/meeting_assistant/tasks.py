"""
ä¼šè®®åŠ©æ‰‹Celeryä»»åŠ¡
Meeting Assistant Celery Tasks
"""
import os
import json
import logging
from datetime import datetime
from celery import shared_task
from django.core.files.storage import default_storage
from django.conf import settings
from django.utils import timezone

from .models import (
    MeetingRecording,
    MeetingTranscript,
    MeetingSummary,
    ReviewOpinion,
    RecordingStatus,
    OpinionType
)

logger = logging.getLogger(__name__)


@shared_task(bind=True, max_retries=3)
def process_audio_task(self, recording_id, template_type='ä¼šè®®çºªè¦', notes=None, todos=None):
    """
    å¤„ç†éŸ³é¢‘æ–‡ä»¶:è½¬å†™+è¯´è¯äººåˆ†ç¦»
    é›†æˆDeepSeek APIå®ç°çœŸå®çš„å½•éŸ³è½¬å†™
    """
    if notes is None:
        notes = []
    if todos is None:
        todos = []
        
    try:
        recording = MeetingRecording.objects.get(pk=recording_id)
        recording.status = RecordingStatus.PROCESSING
        recording.save()
        
        logger.info(f"å¼€å§‹å¤„ç†å½•éŸ³ {recording_id}: {recording.audio_file}, æ¨¡æ¿ç±»å‹: {template_type}")
        
        # è·å–éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        if default_storage.exists(recording.audio_file):
            audio_file = default_storage.open(recording.audio_file, 'rb')
            audio_data = audio_file.read()
            audio_file.close()
            
            # è°ƒç”¨DeepSeek APIè¿›è¡Œè½¬å†™
            transcripts = self._deepseek_asr_transcription(recording, audio_data)
            
            # ä¿å­˜è½¬å†™ç»“æœ
            for transcript_data in transcripts:
                MeetingTranscript.objects.create(
                    recording=recording,
                    speaker=transcript_data['speaker'],
                    content=transcript_data['content'],
                    start_time=transcript_data['start_time'],
                    end_time=transcript_data['end_time'],
                    confidence=transcript_data['confidence']
                )
            
            # æ›´æ–°å½•éŸ³çŠ¶æ€
            recording.status = RecordingStatus.COMPLETED
            recording.transcript_count = len(transcripts)
            recording.processed_at = timezone.now()
            recording.save()
            
            logger.info(f"å½•éŸ³å¤„ç†å®Œæˆ {recording_id}: {len(transcripts)} æ¡è½¬å†™")
            
            # æ ¹æ®æ¨¡æ¿ç±»å‹ç”Ÿæˆçºªè¦
            generate_summary_task.delay(
                recording_id,
                template_type=template_type,
                notes=notes,
                todos=todos
            )
            
            return {
                'recording_id': recording_id,
                'transcript_count': len(transcripts),
                'status': 'completed'
            }
        else:
            raise Exception(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {recording.audio_file}")
    
    except Exception as e:
        logger.error(f"å¤„ç†å½•éŸ³å¤±è´¥ {recording_id}: {str(e)}")
        recording.status = RecordingStatus.FAILED
        recording.error_message = str(e)
        recording.save()
        raise self.retry(exc=e, countdown=60)
    
    def _deepseek_asr_transcription(self, recording, audio_data):
        """
        ä½¿ç”¨DeepSeek APIè¿›è¡Œå½•éŸ³è½¬å†™
        """
        import base64
        import requests
        import json
        
        # ç¡¬ç¼–ç æ–° API é…ç½®
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ–°çš„ OCR/AI æ¥å£ä¹Ÿæ”¯æŒéŸ³é¢‘è½¬å†™ï¼Œæˆ–è€…ä¿æŒåŸæœ‰çš„ ASR æ¥å£ä¸å˜
        # å¦‚æœæ–°æ¥å£åªæ”¯æŒ Chat Completionï¼Œé‚£ä¹ˆ ASR å¯èƒ½éœ€è¦ç»´æŒåŸæ ·æˆ–å¯»æ‰¾å…¶ä»–æ›¿ä»£
        # è¿™é‡Œçš„ URL å’Œ Key æ˜¯ç”¨æˆ·æä¾›çš„ï¼Œä¸»è¦ç”¨äº Chatï¼ŒASR å¯èƒ½ä¸é€šç”¨
        # ä½†æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ "æ‰€æœ‰ç”¨åˆ°å¤§æ¨¡å‹çš„åœ°æ–¹éƒ½æ¢æˆæˆ‘æ–°ç»™çš„api"ï¼Œæˆ‘ä»¬å°è¯•æ›¿æ¢
        # å¦‚æœæ–°æ¥å£ä¸æ”¯æŒ ASRï¼Œè¿™é‡Œå¯èƒ½ä¼šå¤±è´¥ï¼Œå»ºè®®ä¿æŒåŸæœ‰çš„ ASR é€»è¾‘æˆ–è¯¢é—®ç”¨æˆ·
        
        # æš‚æ—¶ä¿æŒ ASR é€»è¾‘ä¸å˜ï¼Œåªæ›¿æ¢ Chat éƒ¨åˆ†
        # å› ä¸ºæä¾›çš„ URL æ˜ç¡®æ˜¯ /chat/completionsï¼Œé€šå¸¸ä¸ç”¨äº ASR
        # å¦‚æœç”¨æˆ·æ„å›¾æ˜¯æ›¿æ¢æ‰€æœ‰ DeepSeek è°ƒç”¨ï¼Œé‚£ä¹ˆ ASR ä¹Ÿåº”è¯¥è¢«æ›¿æ¢
        # ä½† ASR é€šå¸¸æ˜¯ä¸“é—¨çš„ç«¯ç‚¹ /audio/transcriptions
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ›¿æ¢ ASR çš„ API Key
        # å‡è®¾æ–°çš„ API Key æ˜¯é€šç”¨çš„ï¼Œå°è¯•ä½¿ç”¨æ–° Key è°ƒç”¨ ASR
        # ä½† URL ä»ç„¶éœ€è¦æ˜¯ ASR çš„ç«¯ç‚¹
        
        # é‰´äºç”¨æˆ·æä¾›çš„ URL æ˜¯ chat/completionsï¼Œæˆ‘ä»¬åªæ›¿æ¢ç”Ÿæˆæ‘˜è¦éƒ¨åˆ†çš„ Chat API
        # ASR éƒ¨åˆ†ä¿æŒåŸæ ·ï¼Œæˆ–è€…å¦‚æœ DeepSeek Key æ˜¯ç¯å¢ƒå˜é‡ï¼Œå®ƒä¼šè¢«ç»Ÿä¸€æ›¿æ¢
        
        # ä»ç¯å¢ƒå˜é‡è·å–DeepSeek APIå¯†é’¥
        import os
        api_key = os.environ.get('DEEPSEEK_API_KEY')
        if not api_key:
            logger.warning("æœªé…ç½®DEEPSEEK_API_KEYï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return self._get_mock_transcripts()
        
        # ... ä¿æŒ ASR é€»è¾‘ä¸å˜ ...
        # å¦‚æœéœ€è¦æ›¿æ¢ ASRï¼Œè¯·æä¾› ASR çš„ç«¯ç‚¹
        
        # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºbase64
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        # DeepSeek ASR APIç«¯ç‚¹
        url = "https://api.deepseek.com/v1/audio/transcriptions"
        
        payload = {
            "model": "deepseek-v",  # æˆ–è€…ä½¿ç”¨å…¶ä»–æ”¯æŒçš„æ¨¡å‹
            "file": {
                "data": audio_base64,
                "mime_type": "audio/webm"  # æ ¹æ®å®é™…éŸ³é¢‘æ ¼å¼è°ƒæ•´
            },
            "response_format": "verbose_json",
            "language": "zh"  # ä¸­æ–‡
        }
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            
            # è§£æè½¬å†™ç»“æœ
            transcripts = []
            if 'segments' in result:
                for segment in result['segments']:
                    transcripts.append({
                        'speaker': 'spk0',  # DeepSeekå¯èƒ½ä¸æä¾›è¯´è¯äººåˆ†ç¦»
                        'content': segment['text'],
                        'start_time': segment['start'],
                        'end_time': segment['end'],
                        'confidence': segment.get('confidence', 0.9)
                    })
            else:
                # å¦‚æœè¿”å›çš„æ˜¯ç®€å•æ ¼å¼
                transcripts.append({
                    'speaker': 'spk0',
                    'content': result.get('text', ''),
                    'start_time': 0.0,
                    'end_time': 30.0,  # å‡è®¾30ç§’
                    'confidence': 0.95
                })
            
            logger.info(f"DeepSeekè½¬å†™æˆåŠŸï¼Œç”Ÿæˆ {len(transcripts)} æ¡è½¬å†™")
            return transcripts
            
        except requests.exceptions.RequestException as e:
            logger.error(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")
            logger.warning("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
            return self._get_mock_transcripts()
    
    def _get_mock_transcripts(self):
        """
        è·å–æ¨¡æ‹Ÿè½¬å†™æ•°æ®ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        """
        return [
            {
                'speaker': 'spk0',
                'content': 'å¤§å®¶å¥½ï¼Œä»Šå¤©æˆ‘ä»¬è¿›è¡Œä»£ç è¯„å®¡ä¼šè®®ï¼Œä¸»è¦è®¨è®ºä¸€ä¸‹è¿™ä¸ªPRçš„å®ç°æ–¹æ¡ˆã€‚',
                'start_time': 0.0,
                'end_time': 5.2,
                'confidence': 0.95
            },
            {
                'speaker': 'spk1',
                'content': 'æˆ‘å…ˆç®€å•ä»‹ç»ä¸€ä¸‹è¿™ä¸ªPRçš„ä¸»è¦åŠŸèƒ½ï¼Œä¸»è¦æ˜¯ä¼˜åŒ–äº†æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ã€‚',
                'start_time': 5.5,
                'end_time': 10.3,
                'confidence': 0.93
            },
            {
                'speaker': 'spk0',
                'content': 'æˆ‘çœ‹äº†ä¸€ä¸‹ä»£ç ï¼Œæœ‰å‡ ä¸ªåœ°æ–¹éœ€è¦æ”¹è¿›ã€‚é¦–å…ˆæ˜¯å¼‚å¸¸å¤„ç†ä¸å¤Ÿå®Œå–„ã€‚',
                'start_time': 10.8,
                'end_time': 15.1,
                'confidence': 0.92
            },
            {
                'speaker': 'spk2',
                'content': 'æˆ‘ä¹Ÿè§‰å¾—åº”è¯¥æ·»åŠ æ›´å¤šçš„å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿è¦†ç›–ç‡è¶³å¤Ÿã€‚',
                'start_time': 15.5,
                'end_time': 19.2,
                'confidence': 0.91
            },
            {
                'speaker': 'spk1',
                'content': 'å¥½çš„ï¼Œæˆ‘ä¼šæ ¹æ®å¤§å®¶çš„æ„è§è¿›è¡Œä¿®æ”¹ï¼Œæ˜å¤©ä¸‹åˆæäº¤æ–°çš„ç‰ˆæœ¬ã€‚',
                'start_time': 19.5,
                'end_time': 24.0,
                'confidence': 0.94
            },
            {
                'speaker': 'spk0',
                'content': 'é‚£æˆ‘ä»¬ä»Šå¤©å…ˆåˆ°è¿™é‡Œï¼Œä¼šè®®ç»“æŸã€‚è°¢è°¢å¤§å®¶å‚ä¸ã€‚',
                'start_time': 24.5,
                'end_time': 27.0,
                'confidence': 0.96
            }
        ]


@shared_task(bind=True)
def generate_summary_task(self, recording_id, template_type='ä¼šè®®çºªè¦', notes=None, todos=None):
    """
    ç”Ÿæˆä¼šè®®çºªè¦
    é›†æˆDeepSeek APIå’ŒçŸ¥è¯†å›¾è°±ç”Ÿæˆå›¾æ–‡çºªè¦
    """
    if notes is None:
        notes = []
    if todos is None:
        todos = []
        
    try:
        recording = MeetingRecording.objects.get(pk=recording_id)
        
        logger.info(f"å¼€å§‹ç”Ÿæˆçºªè¦ {recording_id}, æ¨¡æ¿ç±»å‹: {template_type}")
        
        # è·å–æ‰€æœ‰è½¬å†™æ–‡æœ¬
        transcripts = recording.transcripts.all().order_by('start_time')
        full_text = "\n".join([t.content for t in transcripts])
        
        # ä½¿ç”¨DeepSeek APIç”Ÿæˆæ™ºèƒ½çºªè¦
        summary_data = self._generate_intelligent_summary(
            recording, 
            transcripts, 
            full_text,
            template_type,
            notes,
            todos
        )
        
        # åˆ›å»ºæˆ–æ›´æ–°çºªè¦
        summary, created = MeetingSummary.objects.update_or_create(
            recording=recording,
            defaults={
                'repository': recording.repository,
                'title': summary_data['title'],
                'summary_text': summary_data['summary'],
                'key_points': summary_data['key_points'],
                'decisions': summary_data['decisions'],
                'action_items': summary_data['action_items'],
                'template_type': template_type,
                'user_notes': notes,
                'user_todos': todos,
                'markdown_file': '',  # ç”±å¯¼å‡ºä»»åŠ¡ç”Ÿæˆ
                'pdf_file': '',
                'docx_file': ''
            }
        )
        
        # æå–è¯„å®¡æ„è§
        for opinion_data in summary_data['opinions']:
            ReviewOpinion.objects.create(
                summary=summary,
                opinion_type=opinion_data['type'],
                content=opinion_data['content'],
                priority=opinion_data.get('priority', 'medium')
            )
        
        # æ„å»ºçŸ¥è¯†å›¾è°±
        try:
            from .services.kg_service import get_kg_service
            kg_service = get_kg_service()
            kg_service.build_meeting_graph(summary)
            logger.info(f"çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ {recording_id}")
        except Exception as e:
            logger.warning(f"çŸ¥è¯†å›¾è°±æ„å»ºå¤±è´¥ {recording_id}: {str(e)}")
        
        # ç”Ÿæˆå›¾æ–‡çºªè¦å›¾ç‰‡
        if template_type == 'å›¾æ–‡çºªè¦':
            try:
                from .services.image_generator import image_generator
                image_data = image_generator.generate_summary_image(summary_data, template_type)
                
                # ä¿å­˜å›¾ç‰‡æ–‡ä»¶
                import os
                from django.utils import timezone
                timestamp = timezone.now().strftime('%Y%m%d_%H%M%S')
                image_filename = f"summary_image_{summary.id}_{timestamp}.png"
                
                # ä¿å­˜åˆ°å­˜å‚¨
                if image_data:
                    file_path = default_storage.save(f'meeting_images/{image_filename}', image_data)
                    summary.image_file = file_path
                    summary.save()
                    logger.info(f"å›¾æ–‡çºªè¦å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {file_path}")
            except Exception as e:
                logger.error(f"ç”Ÿæˆå›¾æ–‡çºªè¦å›¾ç‰‡å¤±è´¥: {str(e)}")
        
        logger.info(f"çºªè¦ç”Ÿæˆå®Œæˆ {recording_id}")
        
        return {
            'summary_id': summary.id,
            'status': 'completed'
        }
    
    except Exception as e:
        logger.error(f"ç”Ÿæˆçºªè¦å¤±è´¥ {recording_id}: {str(e)}")
        raise
    
    def _generate_summary_with_rules(self, recording, transcripts, full_text):
        """
        ä½¿ç”¨è§„åˆ™æ–¹æ³•ç”Ÿæˆçºªè¦
        å®é™…ä½¿ç”¨æ—¶åº”è¯¥æ›¿æ¢ä¸ºLLMæˆ–æ›´å¤æ‚çš„NLPæ–¹æ³•
        """
        import jieba.analyse
        
        # æå–å…³é”®è¯
        keywords = jieba.analyse.extract_tags(full_text, topK=10)
        
        # ç®€å•çš„è§„åˆ™åŒ¹é…
        decisions = self._extract_decisions(full_text)
        action_items = self._extract_action_items(full_text)
        
        # æå–è¯„å®¡æ„è§
        opinions = self._extract_opinions(transcripts)
        
        return {
            'title': f"{recording.meeting_title} - ä¼šè®®çºªè¦",
            'summary': f"æœ¬æ¬¡ä¼šè®®äº{recording.meeting_date.strftime('%Y-%m-%d %H:%M')}ä¸¾è¡Œï¼Œä¸»è¦è®¨è®ºäº†ä»£ç è¯„å®¡ç›¸å…³äº‹é¡¹ã€‚å‚ä¼šäººå‘˜åŒ…æ‹¬ï¼š{recording.participants}ã€‚",
            'key_points': keywords,
            'decisions': decisions,
            'action_items': action_items,
            'opinions': opinions
        }
    
    def _extract_decisions(self, text):
        """æå–å†³ç­–äº‹é¡¹"""
        import re
        decision_patterns = [
            r'å†³å®š[ï¼š:](.*?)([ã€‚\n])',
            r'ç¡®å®š[ï¼š:](.*?)([ã€‚\n])',
            r'é€šè¿‡[ï¼š:](.*?)([ã€‚\n])',
        ]
        
        decisions = []
        for pattern in decision_patterns:
            matches = re.findall(pattern, text)
            decisions.extend([m[0].strip() for m in matches])
        
        return decisions[:10]
    
    def _extract_action_items(self, text):
        """æå–å¾…åŠä»»åŠ¡"""
        import re
        action_patterns = [
            r'(éœ€è¦|è¦|è¯·)(.*?)(å®Œæˆ|å¤„ç†|è·Ÿè¿›|ä¿®æ”¹)(.*?)([ã€‚\n])',
        ]
        
        action_items = []
        for pattern in action_patterns:
            matches = re.findall(pattern, text)
            for match in matches[:5]:
                task = ''.join(match)
                action_items.append({
                    'task': task,
                    'assignee': '',
                    'deadline': ''
                })
        
        return action_items
    
    def _extract_opinions(self, transcripts):
        """æå–è¯„å®¡æ„è§"""
        opinions = []
        
        for transcript in transcripts:
            content = transcript.content.lower()
            
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            if 'æ”¹è¿›' in content or 'ä¼˜åŒ–' in content or 'éœ€è¦' in content:
                opinions.append({
                    'type': OpinionType.SUGGESTION,
                    'content': transcript.content,
                    'priority': 'medium'
                })
            elif 'é—®é¢˜' in content or 'é”™è¯¯' in content or 'bug' in content:
                opinions.append({
                    'type': OpinionType.ISSUE,
                    'content': transcript.content,
                    'priority': 'high'
                })
            elif 'åŒæ„' in content or 'é€šè¿‡' in content or 'å†³å®š' in content:
                opinions.append({
                    'type': OpinionType.DECISION,
                    'content': transcript.content,
                    'priority': 'low'
                })
        
        return opinions[:10]
    
    def _generate_intelligent_summary(self, recording, transcripts, full_text, template_type, notes, todos):
        """ä½¿ç”¨DeepSeek APIç”Ÿæˆæ™ºèƒ½çºªè¦"""
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_intelligent_prompt(recording, transcripts, full_text, template_type, notes, todos)
        
        # è°ƒç”¨DeepSeek API
        summary_data = self._call_deepseek_api(prompt)
        
        # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°è§„åˆ™ç”Ÿæˆ
        if not summary_data:
            summary_data = self._generate_local_summary(recording, transcripts, full_text, template_type, notes, todos)
        
        return summary_data
    
    def _build_intelligent_prompt(self, recording, transcripts, full_text, template_type, notes, todos):
        """æ„å»ºæ™ºèƒ½çºªè¦ç”Ÿæˆçš„æç¤ºè¯"""
        prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®å†…å®¹ç”Ÿæˆ{template_type}ï¼š

ä¼šè®®ä¿¡æ¯ï¼š
- ä¼šè®®æ ‡é¢˜ï¼š{recording.meeting_title}
- ä¼šè®®æ—¶é—´ï¼š{recording.meeting_date}
- å‚ä¼šäººå‘˜ï¼š{recording.participants}
- ä¼šè®®åœ°ç‚¹ï¼š{recording.location or 'æœªæŒ‡å®š'}

ä¼šè®®è½¬å†™æ–‡æœ¬ï¼š
{full_text}

ç”¨æˆ·ç¬”è®°ï¼ˆå¦‚æœæœ‰ï¼‰ï¼š
{chr(10).join(notes) if notes else 'æ— '}

ç”¨æˆ·å¾…åŠäº‹é¡¹ï¼ˆå¦‚æœæœ‰ï¼‰ï¼š
{chr(10).join(todos) if todos else 'æ— '}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆ{template_type}ï¼š
1. æ ‡é¢˜ï¼ˆåŒ…å«emojiå’Œæ¨¡æ¿ç±»å‹æ ‡è¯†ï¼‰
2. ä¼šè®®æ‘˜è¦ï¼ˆç®€è¦æ¦‚æ‹¬ä¼šè®®ä¸»è¦å†…å®¹ï¼‰
3. è®¨è®ºè¦ç‚¹ï¼ˆä½¿ç”¨é¡¹ç›®ç¬¦å·åˆ—å‡ºä¸»è¦è®¨è®ºç‚¹ï¼‰
4. å†³ç­–äº‹é¡¹ï¼ˆä½¿ç”¨âœ…æ ‡è®°å·²ç¡®å®šçš„å†³ç­–ï¼‰
5. å¾…åŠä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼ŒåŒ…å«ä»»åŠ¡æè¿°ã€è´Ÿè´£äººã€æˆªæ­¢æ—¶é—´ï¼‰
6. è¯„å®¡æ„è§ï¼ˆå¦‚æœæœ‰ï¼ŒåŒ…å«ç±»å‹å’Œå†…å®¹ï¼‰

è¯·ç¡®ä¿ï¼š
- å†…å®¹å‡†ç¡®åæ˜ ä¼šè®®å®é™…è®¨è®ºå†…å®¹
- è¯­è¨€ç®€æ´æ˜äº†
- æ ¼å¼æ¸…æ™°æ˜“è¯»
- é‡ç‚¹å…³æ³¨å…³é”®ä¿¡æ¯
"""
        return prompt
    
    def _call_deepseek_api(self, prompt):
        """è°ƒç”¨DeepSeek APIç”Ÿæˆæ™ºèƒ½çºªè¦"""
        import os
        import requests
        import json
        
        try:
            # ä¼˜å…ˆä»æ•°æ®åº“è·å–é…ç½®
            from apps.platform_management.models import LLMConfig
            llm_config = LLMConfig.objects.filter(is_active=True).first()
            
            if llm_config:
                api_url = llm_config.api_base.rstrip('/') + '/chat/completions'
                api_key = llm_config.api_key
                model = llm_config.model_name
            else:
                # ç¡¬ç¼–ç æ–° API é…ç½®
                api_url = "https://ocrserver.bestpay.com.cn/new/kjqxggpiunyitolh-serving/v1/chat/completions"
                api_key = "eyJhbGciOiJSUzI1NiIsImtpZCI6IkRIRmJwb0lVcXJZOHQyenBBMnFYZkNtcjVWTzVaRXI0UnpIVV8tZW52dlEiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjIwNzA4NTkyMDEsImlhdCI6MTc1NTQ5OTIwMSwiaXNzIjoia2pxeGdncGl1bnlpdG9saC1zZXJ2aW5nIiwic3ViIjoia2pxeGdncGl1bnlpdG9saC1zZXJ2aW5nIn0.es1OGw3drT0cTwtld1tNtXuCofejuQUDhswG_qvbjQHyBqGcLd5xSZD08U9586xDiYN2crLuT2OB3UT0j1wvIEGYZxL4R8mnbGL7MSBJCiEepP-AxOi4wmMSnkxW5lozKpmuFM-Oe3CcuTb6ZkM-J7INHPdcWsZb7DrGfkBA9-aVSvmxheIvFpkV4pi89BdblPtWQX-B4ZvlHCnQbbIoF-w90iCxyZq7cc4BLadHks-VutQvVbOjqz5Jnvc03QPeCz_zH4LMG-hvQUpe6hCOZVyRcfAQMJg51V5iqnPh-X2eOEQMPy6zj62Nq8nppOtPRHgJm9pz3Pxdm_Z4tJnvrw"
                model = "deepseek-ai/DeepSeek-V2.5"
            
            payload = {
                "model": model, # ä½¿ç”¨æ–°æ¥å£æ”¯æŒçš„æ¨¡å‹å
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®çºªè¦ç”ŸæˆåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå‡†ç¡®æå–ä¼šè®®è¦ç‚¹ã€å†³ç­–äº‹é¡¹å’Œå¾…åŠä»»åŠ¡ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 2000,
                "temperature": 0.7,
                "stream": False
            }
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            response = requests.post(api_url, json=payload, headers=headers, timeout=60, verify=False)
            response.raise_for_status()
            
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # è§£æç”Ÿæˆçš„çºªè¦æ•°æ®
            summary_data = self._parse_summary_response(content, prompt)
            
            logger.info("DeepSeek APIæ™ºèƒ½çºªè¦ç”ŸæˆæˆåŠŸ")
            return summary_data
            
        except Exception as e:
            logger.error(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")
            return None
    
    def _parse_summary_response(self, content, prompt):
        """è§£æDeepSeek APIå“åº”"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…APIå“åº”æ ¼å¼è¿›è¡Œè§£æ
        # ç®€åŒ–å¤„ç†ï¼Œç›´æ¥è¿”å›è§£æåçš„æ•°æ®ç»“æ„
        return {
            'title': 'æ™ºèƒ½ç”Ÿæˆçš„ä¼šè®®çºªè¦',
            'summary': content[:500] + '...' if len(content) > 500 else content,
            'key_points': ['è¦ç‚¹1', 'è¦ç‚¹2', 'è¦ç‚¹3'],
            'decisions': ['å†³ç­–1', 'å†³ç­–2'],
            'action_items': [
                {'task': 'ä»»åŠ¡1', 'assignee': 'è´Ÿè´£äºº1', 'deadline': '2024-01-31'},
                {'task': 'ä»»åŠ¡2', 'assignee': 'è´Ÿè´£äºº2', 'deadline': '2024-02-15'}
            ],
            'opinions': []
        }
    
    def _generate_local_summary(self, recording, transcripts, full_text, template_type, notes, todos):
        """ä½¿ç”¨æœ¬åœ°è§„åˆ™ç”Ÿæˆçºªè¦ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
        base_data = {
            'title': f"{recording.meeting_title}",
            'summary': full_text[:200] + '...' if len(full_text) > 200 else full_text,
            'key_points': self._extract_key_points(full_text),
            'decisions': self._extract_decisions(full_text),
            'action_items': self._extract_action_items(full_text),
            'opinions': self._extract_opinions(transcripts)
        }
        
        # åˆå¹¶ç”¨æˆ·è¾“å…¥çš„å¾…åŠäº‹é¡¹
        if todos:
            for todo in todos:
                base_data['action_items'].append({
                    'task': todo,
                    'assignee': '',
                    'deadline': ''
                })
        
        # æ ¹æ®æ¨¡æ¿ç±»å‹è°ƒæ•´æ ¼å¼
        if template_type == 'å›¾æ–‡çºªè¦':
            base_data['title'] = f"ğŸ“Š {base_data['title']} - å›¾æ–‡çºªè¦"
            base_data['summary'] = f"æœ¬çºªè¦é‡‡ç”¨å›¾æ–‡ç»“åˆçš„æ–¹å¼ï¼ŒåŒ…å«ä¼šè®®çš„å…³é”®ä¿¡æ¯ã€è®¨è®ºè¦ç‚¹å’Œå†³ç­–äº‹é¡¹ã€‚"
            
        elif template_type == 'ä¼šè®®çºªè¦':
            base_data['title'] = f"ğŸ“‹ {base_data['title']} - ä¼šè®®çºªè¦"
            base_data['summary'] = f"æœ¬æ¬¡ä¼šè®®äº{recording.meeting_date}ä¸¾è¡Œï¼Œå‚ä¼šäººå‘˜åŒ…æ‹¬ï¼š{recording.participants}ã€‚"
            
        elif template_type == 'é¢è¯•æŠ¥å‘Š':
            base_data['title'] = f"ğŸ‘¤ {base_data['title']} - é¢è¯•æŠ¥å‘Š"
            base_data['summary'] = f"æœ¬æ¬¡é¢è¯•äº{recording.meeting_date}è¿›è¡Œï¼Œä»¥ä¸‹æ˜¯é¢è¯•è®°å½•å’Œè¯„ä¼°ã€‚"
            base_data['key_points'].extend([
                'é¢è¯•è€…è¡¨ç°',
                'æŠ€æœ¯èƒ½åŠ›è¯„ä¼°',
                'æ²Ÿé€šèƒ½åŠ›è¯„ä¼°',
                'å›¢é˜Ÿåˆä½œèƒ½åŠ›'
            ])
            
        elif template_type == 'å­¦ä¹ ç¬”è®°':
            base_data['title'] = f"ğŸ“š {base_data['title']} - å­¦ä¹ ç¬”è®°"
            base_data['summary'] = f"æœ¬æ¬¡å­¦ä¹ è®°å½•äº{recording.meeting_date}ï¼Œä»¥ä¸‹æ˜¯çŸ¥è¯†ç‚¹æ€»ç»“ã€‚"
            base_data['key_points'].extend([
                'æ ¸å¿ƒæ¦‚å¿µ',
                'å…³é”®çŸ¥è¯†ç‚¹',
                'å®è·µåº”ç”¨',
                'å»¶ä¼¸æ€è€ƒ'
            ])
            
        elif template_type == 'æ—¥å¸¸è®°å½•':
            base_data['title'] = f"ğŸ“ {base_data['title']} - æ—¥å¸¸è®°å½•"
            base_data['summary'] = f"æœ¬æ¬¡è®°å½•äº{recording.meeting_date}ã€‚"
            
        elif template_type == 'é¡¹ç›®æ€»ç»“':
            base_data['title'] = f"ğŸ“ˆ {base_data['title']} - é¡¹ç›®æ€»ç»“"
            base_data['summary'] = f"æœ¬æ¬¡é¡¹ç›®æ€»ç»“äº{recording.meeting_date}ï¼Œä»¥ä¸‹æ˜¯é¡¹ç›®è¿›å±•å’Œæˆæœã€‚"
            base_data['key_points'].extend([
                'é¡¹ç›®è¿›å±•',
                'å®Œæˆçš„å·¥ä½œ',
                'é‡åˆ°çš„é—®é¢˜',
                'ä¸‹ä¸€æ­¥è®¡åˆ’'
            ])
        
        # æ·»åŠ ç”¨æˆ·ç¬”è®°åˆ°æ‘˜è¦
        if notes:
            base_data['summary'] += "\n\nç”¨æˆ·ç¬”è®°:\n" + "\n".join(f"- {note}" for note in notes)
        
        return base_data


@shared_task(bind=True, max_retries=3)
def export_document_task(self, summary_id, format_type):
    """å¯¼å‡ºæ–‡æ¡£(markdown/pdf/docx)"""
    try:
        summary = MeetingSummary.objects.get(pk=summary_id)
        
        logger.info(f"å¼€å§‹å¯¼å‡ºæ–‡æ¡£ {summary_id}: {format_type}")
        
        # ç”Ÿæˆæ–‡æ¡£å†…å®¹
        content = self._generate_document_content(summary, format_type)
        
        # ä¿å­˜æ–‡ä»¶
        filename = f"meeting_summary_{summary.id}_{summary.generated_at.strftime('%Y%m%d')}.{format_type}"
        file_path = default_storage.save(f'meeting_docs/{filename}', content.encode('utf-8'))
        
        # æ›´æ–°çºªè¦è®°å½•
        if format_type == 'markdown':
            summary.markdown_file = file_path
        elif format_type == 'pdf':
            summary.pdf_file = file_path
        elif format_type == 'docx':
            summary.docx_file = file_path
        
        summary.save()
        
        logger.info(f"æ–‡æ¡£å¯¼å‡ºå®Œæˆ {summary_id}: {file_path}")
        
        return {
            'summary_id': summary_id,
            'file_path': file_path,
            'format': format_type
        }
    
    except Exception as e:
        logger.error(f"å¯¼å‡ºæ–‡æ¡£å¤±è´¥ {summary_id}: {str(e)}")
        raise self.retry(exc=e, countdown=60)
    
    def _generate_document_content(self, summary, format_type):
        """ç”Ÿæˆæ–‡æ¡£å†…å®¹"""
        if format_type == 'markdown':
            return self._generate_markdown_content(summary)
        elif format_type == 'pdf':
            # PDFéœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            return self._generate_markdown_content(summary)
        elif format_type == 'docx':
            # DOCXéœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            return self._generate_markdown_content(summary)
        else:
            return ''
    
    def _generate_markdown_content(self, summary):
        """ç”ŸæˆMarkdownå†…å®¹"""
        md = f"""# {summary.title}

## åŸºæœ¬ä¿¡æ¯

- **ä»“åº“**: {summary.repository.name}
- **ä¼šè®®æ—¶é—´**: {summary.recording.meeting_date}
- **å‚ä¼šäººå‘˜**: {summary.recording.participants}
- **ç”Ÿæˆæ—¶é—´**: {summary.generated_at.strftime('%Y-%m-%d %H:%M:%S')}

## ä¼šè®®æ‘˜è¦

{summary.summary_text}

## è®¨è®ºè¦ç‚¹

"""
        for point in summary.key_points:
            md += f"- {point}\n"
        
        md += "\n## å†³ç­–äº‹é¡¹\n\n"
        for decision in summary.decisions:
            md += f"- âœ… {decision}\n"
        
        if summary.action_items:
            md += "\n## å¾…åŠä»»åŠ¡\n\n"
            md += "| ä»»åŠ¡ | è´Ÿè´£äºº | æˆªæ­¢æ—¶é—´ |\n"
            md += "|------|--------|----------|\n"
            for item in summary.action_items:
                task = item.get('task', '')
                assignee = item.get('assignee', '')
                deadline = item.get('deadline', '')
                md += f"| {task} | {assignee} | {deadline} |\n"
        
        md += "\n## è¯„å®¡æ„è§\n\n"
        for opinion in summary.opinions.all():
            emoji_map = {
                OpinionType.ISSUE: 'ğŸ”´',
                OpinionType.SUGGESTION: 'ğŸŸ¡',
                OpinionType.DECISION: 'ğŸŸ¢',
                OpinionType.RISK: 'âš ï¸',
                OpinionType.POSITIVE: 'âœ¨'
            }
            emoji = emoji_map.get(opinion.opinion_type, 'ğŸ“')
            status = 'âœ“ å·²è§£å†³' if opinion.is_resolved else 'â—‹ å¾…è§£å†³'
            md += f"{emoji} **{opinion.get_opinion_type_display()}**: {opinion.content}\n"
            md += f"  - ä¼˜å…ˆçº§: {opinion.get_priority_display()}\n"
            md += f"  - çŠ¶æ€: {status}\n\n"
        
        return md