# AI智能评审平台 - 详细测试计划 v1.0

## 文档信息

| 版本 | 日期 | 作者 | 变更说明 |
|------|------|------|---------|
| v1.0 | 2026-01-20 | 测试团队 | 初始版本 |

---

## 一、测试概述

### 1.1 项目背景
AI智能评审平台是一个基于AI的智能化代码评审、PRD评审、测试用例生成平台。技术栈为Django 4.2 + Django REST Framework + Celery + PostgreSQL + DeepSeek API。

### 1.2 测试目标
- 验证系统功能正确性
- 确保API接口稳定性和安全性
- 验证AI评审逻辑的准确性
- 验证异步任务处理的可靠性
- 验证系统性能指标

### 1.3 测试范围

#### 测试模块
| 模块 | 测试内容 | 优先级 |
|------|---------|--------|
| 用户认证 | JWT认证、权限验证、角色管理 | P0 |
| 仓库管理 | Git克隆、连接测试、分支管理 | P0 |
| 代码评审 | AI评审、风险评分、反馈机制 | P0 |
| PRD评审 | 文档解析、AI分析、完整性检查 | P1 |
| 测试用例 | 用例生成、Dubbo执行、报告生成 | P1 |
| 数据看板 | 统计报表、图表展示 | P2 |
| 钉钉集成 | 消息推送、签名验证 | P1 |

---

## 二、测试策略

### 2.1 测试类型

#### 2.1.1 单元测试
- 模型测试：验证模型字段、关联关系、验证器
- 序列化器测试：验证数据转换和验证逻辑
- 视图测试：验证业务逻辑和响应格式

#### 2.1.2 API接口测试
- 请求验证：参数校验、必填项、格式验证
- 响应验证：状态码、数据格式、错误信息
- 认证授权：JWT Token、权限控制
- 分页测试：分页参数、边界条件

#### 2.1.3 功能测试
- Git集成测试：仓库克隆、Diff获取、分支扫描
- AI评审测试：评审准确性、风险评分
- 异步任务测试：Celery任务、任务重试
- 外部集成测试：钉钉推送、DeepSeek API

#### 2.1.4 安全测试
- 认证安全：Token过期、Token刷新
- 授权安全：RBAC权限、数据隔离
- 输入安全：SQL注入、XSS攻击
- 数据安全：敏感信息加密、脱敏

#### 2.1.5 性能测试
- 响应时间：API响应时间、页面加载时间
- 并发能力：同时请求数、任务队列处理能力
- 资源占用：内存、CPU、数据库连接

---

## 三、测试环境

### 3.1 环境配置

| 环境 | 用途 | 配置要求 |
|------|------|---------|
| 开发环境 | 本地开发调试 | 本地PostgreSQL + Redis |
| 测试环境 | 功能测试 | Docker Compose部署 |
| 预发布环境 | 集成测试 | 与生产环境一致 |

### 3.2 测试数据准备

#### 测试用户
```python
# 测试用户数据
test_users = [
    {
        'username': 'test_admin',
        'role': 'admin',
        'permissions': ['all']
    },
    {
        'username': 'test_leader',
        'role': 'leader',
        'permissions': ['review', 'repository_manage']
    },
    {
        'username': 'test_developer',
        'role': 'developer',
        'permissions': ['view_review', 'feedback']
    },
    {
        'username': 'test_tester',
        'role': 'tester',
        'permissions': ['test_case', 'execute_test']
    }
]
```

#### 测试仓库
```python
# 测试仓库配置
test_repositories = [
    {
        'name': 'test-project-alpha',
        'git_url': 'https://github.com/test/test-project.git',
        'auth_type': 'password',
        'test_commits': 5
    },
    {
        'name': 'test-project-beta',
        'git_url': 'https://github.com/test/demo-repo.git',
        'auth_type': 'ssh',
        'test_commits': 3
    }
]
```

---

## 四、测试用例设计

### 4.1 用户认证模块测试

#### TC-USER-001: 用户注册
| 用例ID | TC-USER-001 |
|--------|-------------|
| 用例名称 | 用户注册 |
| 前置条件 | 无 |
| 测试步骤 | 1. 请求POST /api/v1/auth/register/ <br>2. 填写用户名、密码、邮箱 |
| 预期结果 | 用户创建成功，返回JWT Token |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-USER-002: 用户登录
| 用例ID | TC-USER-002 |
|--------|-------------|
| 用例名称 | 用户登录 |
| 前置条件 | 用户已注册 |
| 测试步骤 | 1. 请求POST /api/v1/auth/login/ <br>2. 输入用户名、密码 |
| 预期结果 | 登录成功，返回access_token和refresh_token |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-USER-003: Token刷新
| 用例ID | TC-USER-003 |
|--------|-------------|
| 用例名称 | Token刷新 |
| 前置条件 | 用户已登录，获取refresh_token |
| 测试步骤 | 1. 请求POST /api/v1/auth/token/refresh/ <br>2. 传入refresh_token |
| 预期结果 | 获取新的access_token |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-USER-004: 权限验证
| 用例ID | TC-USER-004 |
|--------|-------------|
| 用例名称 | 权限验证 |
| 前置条件 | 普通用户登录 |
| 测试步骤 | 1. 请求POST /api/v1/repositories/ (需要管理员权限) |
| 预期结果 | 返回403 Forbidden |
| 优先级 | P0 |
| 测试类型 | API |

---

### 4.2 仓库管理模块测试

#### TC-REPO-001: 创建仓库
| 用例ID | TC-REPO-001 |
|--------|-------------|
| 用例名称 | 创建仓库 |
| 前置条件 | 管理员登录 |
| 测试步骤 | 1. POST /api/v1/repositories/ <br>2. 填写仓库名称、Git URL、认证信息 |
| 预期结果 | 仓库创建成功，返回仓库信息 |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-REPO-002: 连接测试
| 用例ID | TC-REPO-002 |
|--------|-------------|
| 用例名称 | 仓库连接测试 |
| 前置条件 | 仓库已创建 |
| 测试步骤 | 1. POST /api/v1/repositories/{id}/test-connection/ |
| 预期结果 | 返回连接状态（成功/失败） |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-REPO-003: 仓库同步
| 用例ID | TC-REPO-003 |
|--------|-------------|
| 用例名称 | 仓库同步 |
| 前置条件 | 仓库已创建 |
| 测试步骤 | 1. POST /api/v1/repositories/{id}/sync/ |
| 预期结果 | 触发Celery任务，开始同步 |
| 优先级 | P1 |
| 测试类型 | API |

#### TC-REPO-004: 获取分支列表
| 用例ID | TC-REPO-004 |
|--------|-------------|
| 用例名称 | 获取分支列表 |
| 前置条件 | 仓库已克隆 |
| 测试步骤 | 1. GET /api/v1/repositories/{id}/branches/ |
| 预期结果 | 返回分支列表 |
| 优先级 | P1 |
| 测试类型 | API |

#### TC-REPO-005: 仓库列表筛选
| 用例ID | TC-REPO-005 |
|--------|-------------|
| 用例名称 | 仓库列表筛选 |
| 前置条件 | 多个仓库已创建 |
| 测试步骤 | 1. GET /api/v1/repositories/?is_active=true |
| 预期结果 | 只返回激活的仓库 |
| 优先级 | P2 |
| 测试类型 | API |

---

### 4.3 代码评审模块测试

#### TC-REVIEW-001: 获取评审列表
| 用例ID | TC-REVIEW-001 |
|--------|-------------|
| 用例名称 | 获取评审列表 |
| 前置条件 | 评审记录已存在 |
| 测试步骤 | 1. GET /api/v1/reviews/ |
| 预期结果 | 返回分页的评审列表 |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-REVIEW-002: 评审列表筛选
| 用例ID | TC-REVIEW-002 |
|--------|-------------|
| 用例名称 | 评审列表筛选 |
| 前置条件 | 多个评审记录存在 |
| 测试步骤 | 1. GET /api/v1/reviews/?risk_level=HIGH&repository_id=1 |
| 预期结果 | 只返回高风险且指定仓库的评审 |
| 优先级 | P1 |
| 测试类型 | API |

#### TC-REVIEW-003: 评审详情
| 用例ID | TC-REVIEW-003 |
|--------|-------------|
| 用例名称 | 评审详情 |
| 前置条件 | 评审记录存在 |
| 测试步骤 | 1. GET /api/v1/reviews/{id}/ |
| 预期结果 | 返回完整的评审信息，包括diff_content |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-REVIEW-004: 提交准确反馈
| 用例ID | TC-REVIEW-004 |
|--------|-------------|
| 用例名称 | 提交准确反馈 |
| 前置条件 | 评审记录存在 |
| 测试步骤 | 1. POST /api/v1/reviews/{id}/feedback/ <br>2. body: {"feedback_status": "CORRECT", "comment": "评审准确"} |
| 预期结果 | 反馈提交成功，更新反馈统计 |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-REVIEW-005: 提交误报反馈
| 用例ID | TC-REVIEW-005 |
|--------|-------------|
| 用例名称 | 提交误报反馈 |
| 前置条件 | 评审记录存在 |
| 测试步骤 | 1. POST /api/v1/reviews/{id}/feedback/ <br>2. body: {"feedback_status": "FALSE_POSITIVE", "comment": "误报原因"} |
| 预期结果 | 反馈提交成功，标记为误报 |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-REVIEW-006: 手动触发评审
| 用例ID | TC-REVIEW-006 |
|--------|-------------|
| 用例名称 | 手动触发评审 |
| 前置条件 | 仓库已配置 |
| 测试步骤 | 1. POST /api/v1/reviews/trigger/ <br>2. body: {"repository_id": 1, "branch": "master"} |
| 预期结果 | 触发Celery任务，返回任务ID |
| 优先级 | P1 |
| 测试类型 | API |

#### TC-REVIEW-007: 评审统计
| 用例ID | TC-REVIEW-007 |
|--------|-------------|
| 用例名称 | 评审统计 |
| 前置条件 | 多个评审记录存在 |
| 测试步骤 | 1. GET /api/v1/reviews/statistics/ |
| 预期结果 | 返回总评审数、各风险等级数、准确率 |
| 优先级 | P1 |
| 测试类型 | API |

---

### 4.4 PRD评审模块测试

#### TC-PRD-001: 上传PRD文档
| 用例ID | TC-PRD-001 |
|--------|-------------|
| 用例名称 | 上传PRD文档 |
| 前置条件 | 用户登录 |
| 测试步骤 | 1. POST /api/v1/prd-reviews/ <br>2. multipart/form-data上传文件 |
| 预期结果 | 创建PRD评审记录，触发AI分析 |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-PRD-002: PRD评审详情
| 用例ID | TC-PRD-002 |
|--------|-------------|
| 用例名称 | PRD评审详情 |
| 前置条件 | PRD评审存在 |
| 测试步骤 | 1. GET /api/v1/prd-reviews/{id}/ |
| 预期结果 | 返回完整评审信息，包括AI建议和问题列表 |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-PRD-003: PRD列表筛选
| 用例ID | TC-PRD-003 |
|--------|-------------|
| 用例名称 | PRD列表筛选 |
| 前置条件 | 多个PRD评审存在 |
| 测试步骤 | 1. GET /api/v1/prd-reviews/?review_status=PENDING |
| 预期结果 | 只返回待评审的PRD |
| 优先级 | P1 |
| 测试类型 | API |

---

### 4.5 测试用例模块测试

#### TC-TEST-001: 生成测试用例
| 用例ID | TC-TEST-001 |
|--------|-------------|
| 用例名称 | 生成测试用例 |
| 前置条件 | PRD评审已完成 |
| 测试步骤 | 1. POST /api/v1/test-cases/generate/ <br>2. body: {"prd_review_id": 1} |
| 预期结果 | 触发用例生成任务，返回任务ID |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-TEST-002: 获取用例列表
| 用例ID | TC-TEST-002 |
|--------|-------------|
| 用例名称 | 获取用例列表 |
| 前置条件 | 测试用例存在 |
| 测试步骤 | 1. GET /api/v1/test-cases/ |
| 预期结果 | 返回分页的用例列表 |
| 优先级 | P0 |
| 测试类型 | API |

#### TC-TEST-003: 执行测试
| 用例ID | TC-TEST-003 |
|--------|-------------|
| 用例名称 | 执行测试 |
| 前置条件 | 测试用例存在，配置了Dubbo |
| 测试步骤 | 1. POST /api/v1/test-cases/execute/ <br>2. body: {"case_ids": [1, 2, 3]} |
| 预期结果 | 触发测试执行任务，返回批次ID |
| 优先级 | P1 |
| 测试类型 | API |

#### TC-TEST-004: 获取测试报告
| 用例ID | TC-TEST-004 |
|--------|-------------|
| 用例名称 | 获取测试报告 |
| 前置条件 | 测试执行完成 |
| 测试步骤 | 1. GET /api/v1/test-reports/{batch_id}/ |
| 预期结果 | 返回测试报告，包括通过率、失败详情 |
| 优先级 | P1 |
| 测试类型 | API |

---

### 4.6 数据看板模块测试

#### TC-DASH-001: 评审趋势统计
| 用例ID | TC-DASH-001 |
|--------|-------------|
| 用例名称 | 评审趋势统计 |
| 前置条件 | 评审记录存在 |
| 测试步骤 | 1. GET /api/v1/dashboard/reviews/trend/?days=7 |
| 预期结果 | 返回7天内的评审趋势数据 |
| 优先级 | P1 |
| 测试类型 | API |

#### TC-DASH-002: 风险分布统计
| 用例ID | TC-DASH-002 |
|--------|-------------|
| 用例名称 | 风险分布统计 |
| 前置条件 | 评审记录存在 |
| 测试步骤 | 1. GET /api/v1/dashboard/reviews/distribution/ |
| 预期结果 | 返回高/中/低风险的分布数据 |
| 优先级 | P1 |
| 测试类型 | API |

#### TC-DASH-003: 仓库质量排名
| 用例ID | TC-DASH-003 |
|--------|-------------|
| 用例名称 | 仓库质量排名 |
| 前置条件 | 多个仓库的评审记录存在 |
| 测试步骤 | 1. GET /api/v1/dashboard/repositories/ranking/ |
| 预期结果 | 返回仓库质量排名 |
| 优先级 | P2 |
| 测试类型 | API |

---

## 五、异步任务测试

### 5.1 Celery任务测试

#### TC-CELERY-001: 代码评审任务
| 用例ID | TC-CELERY-001 |
|--------|-------------|
| 用例名称 | 代码评审任务执行 |
| 前置条件 | 仓库已配置，Git仓库存在 |
| 测试步骤 | 1. 手动触发code_review_task |
| 预期结果 | 任务成功执行，创建评审记录 |
| 优先级 | P0 |
| 测试类型 | 功能 |

#### TC-CELERY-002: 任务重试机制
| 用例ID | TC-CELERY-002 |
|--------|-------------|
| 用例名称 | 任务失败重试 |
| 前置条件 | Git服务不可用 |
| 测试步骤 | 1. 触发代码评审任务 |
| 预期结果 | 任务失败，60秒后自动重试 |
| 优先级 | P1 |
| 测试类型 | 功能 |

#### TC-CELERY-003: 批量扫描任务
| 用例ID | TC-CELERY-003 |
|--------|-------------|
| 用例名称 | 批量扫描仓库 |
| 前置条件 | 多个仓库已配置 |
| 测试步骤 | 1. 触发scan_all_repositories任务 |
| 预期结果 | 为每个仓库创建评审任务 |
| 优先级 | P1 |
| 测试类型 | 功能 |

---

## 六、安全测试

### 6.1 认证安全

#### TC-SEC-001: Token过期处理
| 用例ID | TC-SEC-001 |
|--------|-------------|
| 用例名称 | Token过期 |
| 前置条件 | Token已过期 |
| 测试步骤 | 1. 使用过期Token请求API |
| 预期结果 | 返回401 Unauthorized |
| 优先级 | P0 |
| 测试类型 | 安全 |

#### TC-SEC-002: 无效Token处理
| 用例ID | TC-SEC-002 |
|--------|-------------|
| 用例名称 | 无效Token |
| 前置条件 | 无 |
| 测试步骤 | 1. 使用伪造Token请求API |
| 预期结果 | 返回401 Unauthorized |
| 优先级 | P0 |
| 测试类型 | 安全 |

### 6.2 授权安全

#### TC-SEC-003: 越权访问
| 用例ID | TC-SEC-003 |
|--------|-------------|
| 用例名称 | 越权访问其他用户数据 |
| 前置条件 | 用户A登录 |
| 测试步骤 | 1. 请求用户B的评审详情 |
| 预期结果 | 返回404或403（数据隔离） |
| 优先级 | P0 |
| 测试类型 | 安全 |

#### TC-SEC-004: 权限提升
| 用例ID | TC-SEC-004 |
|--------|-------------|
| 用例名称 | 普通用户尝试管理员操作 |
| 前置条件 | 普通用户登录 |
| 测试步骤 | 1. 请求创建仓库 |
| 预期结果 | 返回403 Forbidden |
| 优先级 | P0 |
| 测试类型 | 安全 |

### 6.3 输入安全

#### TC-SEC-005: SQL注入防护
| 用例ID | TC-SEC-005 |
|--------|-------------|
| 用例名称 | SQL注入攻击 |
| 前置条件 | 无 |
| 测试步骤 | 1. 在请求参数中注入SQL |
| 预期结果 | 参数被转义，不执行恶意SQL |
| 优先级 | P0 |
| 测试类型 | 安全 |

#### TC-SEC-006: XSS防护
| 用例ID | TC-SEC-006 |
|--------|-------------|
| 用例名称 | XSS攻击 |
| 前置条件 | 无 |
| 测试步骤 | 1. 在反馈评论中提交<script>标签 |
| 预期结果 | 脚本被转义或过滤 |
| 优先级 | P0 |
| 测试类型 | 安全 |

---

## 七、性能测试

### 7.1 响应时间测试

#### TC-PERF-001: API响应时间
| 用例ID | TC-PERF-001 |
|--------|-------------|
| 用例名称 | API响应时间 |
| 前置条件 | 系统正常运行 |
| 测试步骤 | 1. 连续请求API 100次，测量响应时间 |
| 预期结果 | 95%的请求响应时间 < 500ms |
| 优先级 | P1 |
| 测试类型 | 性能 |

#### TC-PERF-002: 评审生成时间
| 用例ID | TC-PERF-002 |
|--------|-------------|
| 用例名称 | 评审生成时间 |
| 前置条件 | 仓库已配置 |
| 测试步骤 | 1. 触发代码评审任务 |
| 预期结果 | 单次评审 < 60秒 |
| 优先级 | P1 |
| 测试类型 | 性能 |

### 7.2 并发测试

#### TC-PERF-003: API并发能力
| 用例ID | TC-PERF-003 |
|--------|-------------|
| 用例名称 | API并发请求 |
| 前置条件 | 系统正常运行 |
| 测试步骤 | 1. 使用50个并发用户请求API |
| 预期结果 | 所有请求正常返回，无错误 |
| 优先级 | P1 |
| 测试类型 | 性能 |

#### TC-PERF-004: 任务队列处理
| 用例ID | TC-PERF-004 |
|--------|-------------|
| 用例名称 | 任务队列处理 |
| 前置条件 | 多个评审任务等待 |
| 测试步骤 | 1. 触发10个并发评审任务 |
| 预期结果 | 所有任务正常完成 |
| 优先级 | P1 |
| 测试类型 | 性能 |

---

## 八、测试用例清单

### 8.1 按优先级分类

| 优先级 | 用例数量 | 测试类型 |
|--------|---------|---------|
| P0 | 25 | API、功能、安全 |
| P1 | 35 | API、功能、性能 |
| P2 | 15 | API、功能 |

### 8.2 按模块分类

| 模块 | P0用例 | P1用例 | P2用例 |
|------|-------|-------|-------|
| 用户认证 | 4 | 1 | 0 |
| 仓库管理 | 4 | 3 | 1 |
| 代码评审 | 7 | 4 | 0 |
| PRD评审 | 3 | 2 | 0 |
| 测试用例 | 4 | 3 | 0 |
| 数据看板 | 0 | 3 | 3 |
| 异步任务 | 2 | 2 | 0 |
| 安全测试 | 6 | 0 | 0 |
| 性能测试 | 0 | 4 | 0 |
| **合计** | **30** | **22** | **4** |

---

## 九、测试工具

### 9.1 测试框架
- **单元测试**: pytest + pytest-django
- **API测试**: pytest + requests
- **性能测试**: locust / wrk
- **代码覆盖率**: pytest-cov

### 9.2 测试命令

```bash
# 运行所有测试
pytest

# 运行指定模块测试
pytest tests/test_code_review/

# 生成覆盖率报告
pytest --cov=apps --cov-report=html

# 运行性能测试
locust -f tests/performance/locustfile.py

# 运行安全测试
pytest tests/security/
```

---

## 十、测试执行计划

### 10.1 测试阶段

| 阶段 | 时间 | 内容 |
|------|------|------|
| 第一阶段 | Day 1-2 | 单元测试、API基础测试 |
| 第二阶段 | Day 3-4 | 功能测试、集成测试 |
| 第三阶段 | Day 5 | 安全测试、性能测试 |
| 第四阶段 | Day 6 | 回归测试、缺陷修复 |
| 第五阶段 | Day 7 | 测试报告编写 |

### 10.2 测试里程碑

| 里程碑 | 时间 | 交付物 |
|--------|------|--------|
| M1: 测试环境就绪 | Day 1 | 环境部署完成、测试数据准备完成 |
| M2: P0用例执行完成 | Day 3 | P0用例100%通过 |
| M3: 所有用例执行完成 | Day 5 | 测试用例执行率100% |
| M4: 测试报告完成 | Day 7 | 完整的测试报告 |

---

## 十一、缺陷管理

### 11.1 缺陷等级

| 等级 | 定义 | 响应时间 | 解决时间 |
|------|------|---------|---------|
| P0-致命 | 系统崩溃、核心功能不可用 | 立即 | 4小时 |
| P1-严重 | 主要功能异常、数据丢失 | 2小时 | 8小时 |
| P2-一般 | 次要功能异常、显示问题 | 4小时 | 24小时 |
| P3-轻微 | 体验问题、建议优化 | 8小时 | 72小时 |

### 11.2 缺陷报告模板

```markdown
## 缺陷标题

### 基本信息
- 缺陷ID: BUG-XXX
- 优先级: P0/P1/P2/P3
- 模块: 代码评审
- 环境: 测试环境

### 问题描述
[详细描述问题]

### 复现步骤
1. [步骤1]
2. [步骤2]
3. [步骤3]

### 预期结果
[期望的行为]

### 实际结果
[实际的行为]

### 截图/日志
[相关截图或日志]

### 测试数据
[相关的测试数据]
```

---

## 十二、风险与应对

### 12.1 测试风险

| 风险 | 影响 | 应对措施 |
|------|------|---------|
| AI API调用失败 | 评审功能不可用 | 使用Mock替代，准备备用模型 |
| Git仓库访问受限 | 无法测试Git集成 | 准备测试用Git仓库 |
| 外部服务不稳定 | 测试结果不稳定 | 添加重试机制，使用Mock服务 |
| 测试环境资源不足 | 性能测试不准确 | 优化环境配置，分布式测试 |

---

## 附录

### A. 测试数据SQL脚本
[见tests/fixtures/]

### B. 测试配置文件
[见tests/conftest.py]

### C. CI/CD配置
[见.github/workflows/tests.yml]

---

**文档状态**: 待评审
**最后更新**: 2026-01-20
**联系人**: 测试团队
